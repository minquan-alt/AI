{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats and Dogs Classification\n",
    "<h4> Traditional Machine Learning With Logistic Regression </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy path\n",
    "data_folder = '/Users/minhquang/Documents/Learning/AI/data/kagglecatsanddogs_5340/PetImages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cat', 'Dog']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_lazy(data_folder, target_size=(128, 128)):\n",
    "    '''\n",
    "    data_folder: folder contains all of dataset\n",
    "    -return: images (array), labels\n",
    "    target_size: fixed size for all images\n",
    "    '''\n",
    "    for label in os.listdir(data_folder):\n",
    "        folder_path = os.path.join(data_folder, label) # take directory of each label\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        img = img.convert('RGB')\n",
    "                        img = img.resize(target_size)\n",
    "                        img_array = np.asarray(img)\n",
    "                        yield img_array, label\n",
    "                except Exception as e:\n",
    "                    print(f\"Can't process the file image: {e}\")\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_folder):\n",
    "    X, y = [], []\n",
    "    count_label = 0\n",
    "    classes = {}\n",
    "    for img_array, label in load_image_lazy(data_folder):\n",
    "        yi = None\n",
    "        X.append(img_array)\n",
    "        if label not in classes:\n",
    "            classes[label] = count_label\n",
    "            count_label += 1\n",
    "        y.append(classes[label])\n",
    "    return np.array(X), np.array(y), classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't process the file image: cannot identify image file '/Users/minhquang/Documents/Learning/AI/MachineLearning/LogisticRegression/kagglecatsanddogs_5340/PetImages/Cat/Thumbs.db'\n",
      "Can't process the file image: cannot identify image file '/Users/minhquang/Documents/Learning/AI/MachineLearning/LogisticRegression/kagglecatsanddogs_5340/PetImages/Cat/666.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minhquang/Documents/Learning/AI/AI.venv/lib/python3.13/site-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't process the file image: cannot identify image file '/Users/minhquang/Documents/Learning/AI/MachineLearning/LogisticRegression/kagglecatsanddogs_5340/PetImages/Dog/Thumbs.db'\n",
      "Can't process the file image: cannot identify image file '/Users/minhquang/Documents/Learning/AI/MachineLearning/LogisticRegression/kagglecatsanddogs_5340/PetImages/Dog/11702.jpg'\n"
     ]
    }
   ],
   "source": [
    "X_orig, y_orig, classes = load_data(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_orig shape: (24998, 128, 128, 3)\n",
      "y_orig shape: (24998,)\n",
      "Classes mapping: {'Cat': 0, 'Dog': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"X_orig shape:\", X_orig.shape)\n",
    "print(\"y_orig shape:\", y_orig.shape)\n",
    "print(\"Classes mapping:\", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standardize = X_orig/255.\n",
    "X = X_standardize.reshape(X_standardize.shape[0], -1).T\n",
    "y = y_orig.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (49152, 24998)\n",
      "y shape: (1, 24998)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    def propagate(self):\n",
    "        m = self.X.shape[1]\n",
    "        z = self.w.T @ self.X + self.b\n",
    "        yhat = self.sigmoid(z)\n",
    "        cost = (-1/m) * np.sum(self.y * np.log(yhat) + (1 - self.y) * np.log(1 - yhat))\n",
    "        \n",
    "        dw = (1/m) * (self.X @ (yhat - self.y).T)\n",
    "        db = (1/m) * np.sum(yhat - self.y)\n",
    "        \n",
    "        grads = {\n",
    "            \"dw\": dw,\n",
    "            \"db\": db\n",
    "        }\n",
    "        return grads, cost\n",
    "    def optimize(self, epochs=1000, lr=1e-3, decay_rate=0.9):\n",
    "        costs = []\n",
    "        for i in range(epochs):\n",
    "            grads, cost = self.propagate()\n",
    "            dw = grads[\"dw\"]\n",
    "            db = grads[\"db\"]\n",
    "            self.w -= lr * dw\n",
    "            self.b -= lr * db\n",
    "            costs.append(cost)\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Cost at epoch {i+1}: {cost}\")\n",
    "            lr *= decay_rate\n",
    "        return costs\n",
    "    def predict(self, X):\n",
    "        threshold = 0.5\n",
    "        prediction = np.zeros((1, X.shape[1]))\n",
    "        \n",
    "        z = self.w.T @ X + self.b\n",
    "        yhat = self.sigmoid(z)\n",
    "        \n",
    "        for i in range(X.shape[1]):\n",
    "            if yhat[0, i] >= threshold:\n",
    "                prediction[0, i] = 1 # dog\n",
    "            else:\n",
    "                prediction[0, i] = 0 # cat\n",
    "        return prediction\n",
    "    def score(self, X, y):\n",
    "        prediction = self.predict(X)\n",
    "        accuracy = 100 * np.sum(y == prediction) / y.shape[1]\n",
    "        return accuracy\n",
    "        \n",
    "    def fit(self, X, y, lr=1e-3, decay_rate=0.9, epochs=1000):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.w = np.zeros((X.shape[0], 1))\n",
    "        self.b = 0\n",
    "        self.optimize(epochs, lr, decay_rate)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.T, y.T, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24998)\n",
      "(49152, 24998)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 1: 0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train.T, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(50.12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test.T, y_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape sau PCA: (100, 24998)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 100  \n",
    "pca = PCA(n_components=n_components)\n",
    "X_reduced = pca.fit_transform(X.T).T \n",
    "\n",
    "print(\"X shape sau PCA:\", X_reduced.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced.T, y.T, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 1: 0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train.T, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(56.28)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test.T, y_test.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> The accuracy is so low although using the PCA for feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i> Let try it again with Deep Learning </i></b> <br><br>\n",
    "-> DeepLearning/Project/cats_and_dogs_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
